# AI App Argenova - GÃ¼ncellemeler

## ğŸš€ YapÄ±lan GÃ¼ncellemeler

### 1. **Model GÃ¼ncellemeleri**

-   **Chat Modeli**: `llama3.2:7b` â†’ `llama3` (varsayÄ±lan)
-   **Embedding Modeli**: `mxbai-embed-large` â†’ `all-minilm`
-   **Vector Boyutu**: 1024 â†’ 384 (all-minilm iÃ§in)

### 2. **Docker Compose GÃ¼ncellemeleri**

-   **Production**: `docker-compose.yml` - Ollama servisi eklendi
-   **Development**: `docker-compose.dev.yml` - Yeni dosya oluÅŸturuldu
-   **Environment Variables**: Ollama konfigÃ¼rasyonlarÄ± eklendi
-   **Volumes**: Ollama modelleri iÃ§in kalÄ±cÄ± depolama

### 3. **KonfigÃ¼rasyon GÃ¼ncellemeleri**

-   **AI Config**: `OLLAMA_CHAT_MODEL` ve `OLLAMA_EMBEDDING_MODEL` ayrÄ±ldÄ±
-   **Qdrant Config**: Dinamik vector boyutu kontrolÃ¼ eklendi
-   **Embedding Config**: Environment variable desteÄŸi eklendi

### 4. **Yeni Ã–zellikler**

-   **Health Check Endpoint**: `/api/health` - Servis durumu kontrolÃ¼
-   **Model Setup Script**: `npm run setup:models` - Otomatik model indirme
-   **Docker Scripts**: Development ve production iÃ§in ayrÄ± komutlar

### 5. **Environment Variables**

```env
# Yeni deÄŸiÅŸkenler
OLLAMA_URL=http://localhost:11434/api
OLLAMA_CHAT_MODEL=llama3
OLLAMA_EMBEDDING_MODEL=all-minilm
AI_TEMPERATURE=0.7
AI_MAX_TOKENS=512
```

## ğŸ› ï¸ KullanÄ±m

### Development OrtamÄ±

```bash
# Docker ile (Ã¶nerilen)
npm run docker:dev

# Manuel
npm install
cp env.example .env
npm run setup:models
npm run dev
```

### Production OrtamÄ±

```bash
# Docker ile
npm run docker:prod

# Manuel
npm start
```

### Model Kurulumu

```bash
# Otomatik (Ã¶nerilen)
npm run setup:models

# Manuel
ollama pull llama3
ollama pull all-minilm
```

## ğŸ“Š Model KarÅŸÄ±laÅŸtÄ±rmasÄ±

| Model          | Boyut | RAM | VektÃ¶r Boyutu | HÄ±z    | Kalite |
| -------------- | ----- | --- | ------------- | ------ | ------ |
| **llama3**     | 8B    | 8GB | -             | âš¡âš¡   | ğŸŸ¢     |
| **all-minilm** | 91MB  | -   | 384           | âš¡âš¡âš¡ | ğŸŸ¢     |

## ğŸ”§ Docker Servisleri

-   **backend**: Node.js uygulamasÄ±
-   **mongodb**: VeritabanÄ±
-   **qdrant**: VektÃ¶r veritabanÄ±
-   **ollama**: AI modelleri

## ğŸ“ Notlar

-   Qdrant koleksiyonu otomatik olarak doÄŸru vector boyutu ile oluÅŸturulur
-   Ollama modelleri Docker volume'da kalÄ±cÄ± olarak saklanÄ±r
-   Health check endpoint tÃ¼m servislerin durumunu kontrol eder
-   Development ve production ortamlarÄ± ayrÄ± Docker Compose dosyalarÄ± ile yÃ¶netilir
