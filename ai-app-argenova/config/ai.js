const axios = require("axios");

const AI_CONFIG = {
    baseURL: "http://localhost:11434/api",
    model: "phi3:mini", // En kÃ¼Ã§Ã¼k ve hÄ±zlÄ± model
    defaultParams: {
        temperature: parseFloat(process.env.AI_TEMPERATURE) || 0.7,
        max_tokens: parseInt(process.env.AI_MAX_TOKENS) || 512,
    },
};

const queryAI = async (prompt) => {
    try {
        console.log("ğŸ¤– Ollama API'ye istek gÃ¶nderiliyor...");

        const response = await axios.post(
            `${AI_CONFIG.baseURL}/generate`,
            {
                model: AI_CONFIG.model,
                prompt: prompt, // Direkt olarak gelen prompt'u kullan
                temperature: AI_CONFIG.defaultParams.temperature,
                max_tokens: AI_CONFIG.defaultParams.max_tokens,
                stream: false,
            },
            {
                headers: {
                    "Content-Type": "application/json",
                },
                timeout: 300000, // 5 dakika timeout
            }
        );

        console.log("âœ… Ollama yanÄ±tÄ± alÄ±ndÄ±");

        return {
            choices: [
                {
                    text: response.data.response.trim(),
                },
            ],
        };
    } catch (error) {
        console.error("âŒ Ollama API hatasÄ±:", error.message);

        if (error.code === "ECONNREFUSED") {
            throw new Error(
                "Ollama servisi Ã§alÄ±ÅŸmÄ±yor. LÃ¼tfen 'ollama serve' komutunu Ã§alÄ±ÅŸtÄ±rÄ±n."
            );
        }

        if (
            error.code === "ECONNABORTED" ||
            error.message.includes("timeout")
        ) {
            throw new Error(
                "Ollama modeli yanÄ±t vermek iÃ§in Ã§ok uzun sÃ¼rdÃ¼. LÃ¼tfen daha sonra tekrar deneyin."
            );
        }

        throw new Error(`AI servis hatasÄ±: ${error.message}`);
    }
};

module.exports = {
    queryAI,
    AI_CONFIG,
};
